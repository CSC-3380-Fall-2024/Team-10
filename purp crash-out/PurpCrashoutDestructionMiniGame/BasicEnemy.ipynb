{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa625fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from npc_base import GeneralNPC_AI  # Import the base AI model\n",
    "from torch_geometric.data import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f550279b",
   "metadata": {},
   "outputs": [],
   "source": [
    "states = (\"Wander\",\"Still\", \"Interact\",\"Charge\", \"Attack\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e13241e",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (2393897256.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    class BasicAI(GeneralNPC_AI):\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "class BasicEnemyAI(nn.Module):\n",
    "    \"\"\"AI model to predict the best state-action pair.\"\"\"\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(BasicEnemyAI, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, state):\n",
    "        x = torch.relu(self.fc1(state))\n",
    "        q_values = self.fc2(x)\n",
    "        return q_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e1f3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicEnemy(NPC):\n",
    "    def __init__(self, map_size, learning_rate=0.01):\n",
    "        super().__init__(health=1, input_dim=4, hidden_dim=8, num_actions=4, map_size=map_size)\n",
    "        self.position = (random.randint(0, map_size - 1), random.randint(0, map_size - 1))\n",
    "        self.ai_model = BasicEnemyAI(input_dim=4, hidden_dim=16, output_dim=4)  # 4 states/actions\n",
    "        self.optimizer = optim.Adam(self.ai_model.parameters(), lr=learning_rate)\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.state = \"Still\"\n",
    "        self.action_space = [\"Wander\", \"Still\", \"Charge\", \"Attack\"]\n",
    "\n",
    "    def get_state(self, player_position):\n",
    "        \"\"\"Convert the current state into a tensor input.\"\"\"\n",
    "        px, py = player_position\n",
    "        nx, ny = self.position\n",
    "        return torch.tensor([px - nx, py - ny, nx, ny], dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "    def choose_action(self, state, epsilon=0.1):\n",
    "        \"\"\"Epsilon-greedy action selection.\"\"\"\n",
    "        if random.random() < epsilon:  # Explore with probability epsilon\n",
    "            return random.choice(range(4))\n",
    "        else:  # Exploit based on learned Q-values\n",
    "            with torch.no_grad():\n",
    "                q_values = self.ai_model(state)\n",
    "                return torch.argmax(q_values).item()\n",
    "\n",
    "    def update_q_values(self, state, action, reward, next_state, gamma=0.99):\n",
    "        \"\"\"Update Q-values using Bellman Equation.\"\"\"\n",
    "        self.optimizer.zero_grad()\n",
    "        q_values = self.ai_model(state)\n",
    "        next_q_values = self.ai_model(next_state).detach()\n",
    "        target = q_values.clone()\n",
    "        target[0, action] = reward + gamma * torch.max(next_q_values)\n",
    "        loss = self.criterion(q_values, target)\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "    def move(self, action):\n",
    "        \"\"\"Execute the action: Wander, Charge, Attack, or Stay Still.\"\"\"\n",
    "        if self.action_space[action] == \"Wander\":\n",
    "            self.move_randomly()\n",
    "            print(f\"BasicEnemy wanders to {self.position}\")\n",
    "        elif self.action_space[action] == \"Charge\":\n",
    "            self.move_toward_player(player_position)\n",
    "            print(f\"BasicEnemy charges toward {player_position}\")\n",
    "        elif self.action_space[action] == \"Attack\":\n",
    "            print(\"BasicEnemy attacks the player with a melee attack!\")\n",
    "        elif self.action_space[action] == \"Still\":\n",
    "            print(\"BasicEnemy stays still.\")\n",
    "\n",
    "    def move_randomly(self):\n",
    "        \"\"\"Helper function for wandering.\"\"\"\n",
    "        x, y = self.position\n",
    "        move_options = [(x + 1, y), (x - 1, y), (x, y + 1), (x, y - 1)]\n",
    "        valid_moves = [(nx, ny) for nx, ny in move_options \n",
    "                       if 0 <= nx < self.ai_model.map_size and 0 <= ny < self.ai_model.map_size]\n",
    "        if valid_moves:\n",
    "            self.position = random.choice(valid_moves)\n",
    "\n",
    "    def move_toward_player(self, player_position):\n",
    "        \"\"\"Move one step closer to the player.\"\"\"\n",
    "        px, py = player_position\n",
    "        nx, ny = self.position\n",
    "        if px > nx:\n",
    "            self.position = (nx + 1, ny)\n",
    "        elif px < nx:\n",
    "            self.position = (nx - 1, ny)\n",
    "        elif py > ny:\n",
    "            self.position = (nx, ny + 1)\n",
    "        elif py < ny:\n",
    "            self.position = (nx, ny - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7948dc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_size = 10\n",
    "basic_enemy = BasicEnemy(map_size)\n",
    "player_position = (5, 5)\n",
    "\n",
    "# Simulate behavior with AI decision-making\n",
    "for _ in range(10):\n",
    "    state = basic_enemy.get_state(player_position)\n",
    "    action = basic_enemy.choose_action(state)\n",
    "    basic_enemy.move(action)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
